{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyD6OQlDYhU0"
      },
      "source": [
        "updated pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GomHa6ZmPjon",
        "outputId": "aca94644-f9e8-4443-cbde-1bfbbf09bc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/136.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m \u001b[32m133.1/136.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q groq\n",
        "!pip install -q langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZDLb6RMYitD",
        "outputId": "14ae6140-a249-4b5a-ebe9-e8c8d882a1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (1.0.5)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.3->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Run this in a notebook cell first (only once)\n",
        "!pip install -U langchain-huggingface langchain-community sentence-transformers faiss-cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q86D_AWxY1Ig"
      },
      "source": [
        "Complete upgraded pipeline (single cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "50dc850c5fe445d5abe79b3e1fbe0f0a",
            "a7b02cddf4724438bc4f09c4a4d3d02e",
            "6d9f035d698d457c842ce7931985d6b3",
            "9e0730ee55f249369ec68aa649b04a09",
            "5366a7119c9d42bba5e226c2b04c69ca",
            "a4ba955c6ed34231ba630c8d3a841c18",
            "62c717d3f1c94f58ac97b4cb595e797e",
            "22f89912d75548b39539a52a01f83502",
            "45080eafe5d343acbd49afe86e10771e",
            "9ea3acdc3ad1443bac0ca9bde674e061",
            "3c46d13208cd417f9996116dfe70d452",
            "dea89111ca404469ba247c060b00bdad",
            "430698f870df455f8b8e9f170822800f",
            "65c86c87c92b4070b6e7988a8d135b3b",
            "597da5e0e51c4c0489dfaf6218b92e63",
            "2509c2974bce431d95d2085bc1690844",
            "033bef431a494b79a0bbb920895bed34",
            "613f16d22f8043caa7b9f69c9b2e938e",
            "dba1fc9f6dc2447e907b9b02e7b357f2",
            "fd902c47cf2b488f8152fcee7890d213",
            "f392d8bf94ed4bf496d95d993413dc49",
            "0272428de01a4cd7bc70039eeee68973",
            "b6404e354eb04b98a315ad50e597128a",
            "d3ae2e8415c749abbb5e903738be1f0b",
            "ae45105cac80420883901a86faf5d2a9",
            "705db54a06c04ccc9f863d3e52806a65",
            "7737c61a95454382af01967da2ab333f",
            "bcd416b26a1444be80bcaf10466bb4c1",
            "469b1af3365a42cb85b4ea660f6b6365",
            "9d9e54c1d2ce4d8d915edf60f01bbcc8",
            "748682f363d74c40a0bd23ca1df1766e",
            "e202a0abf3c54e09aad5c348fcc9c35f",
            "6a62971dc2ee4702bca482a3160ffe3a",
            "80a6ea88b75d4349821bdaa4e122db94",
            "e0200e1d97714015bf3d83cfc20d78bd",
            "4547c2f7b4864d33b9630a513b9015d0",
            "f083c1c1806c4d1d8d4ff20ddc8c0a0e",
            "d4a1d3e0eeec40308904c7c0218b1b5d",
            "b1336e4ee81e4a5cad048ae523c20d52",
            "b9309a427cc1457c9e5db9c070171080",
            "65e6b6f7bf1048b9aba8b771fe090806",
            "b7215d09b5ef457da5d482d9f6c0ea81",
            "a5bbd5e8d83b413ca0925eaa67eb6d68",
            "92625b557325490dbc9f3933e3b6912a",
            "b4fa8172bdaf442082b20482e7d5291f",
            "e6ab20c4ce5a4b8f946508e980616965",
            "3573bd22e0324a018304278f10194838",
            "4f2c4b8b52764c56b26aab0cc5b36635",
            "ef96ca88a78e49879a82eac38dff5300",
            "4354608e792f4df6927e4787ac180478",
            "a05cf305114c4421af14d63d24f2b009",
            "0d2784b3bb7f459a8ed296f51e7453fb",
            "3d5688f93bdd4e11bc6216f61055d1d6",
            "15c2b5ce19eb4fbc83173ecf06486ea6",
            "01d59612b4014a24acb9d5655a67e4ff",
            "9c4cabc2cb874b019e469d16c17cc260",
            "4f4b835549784f4380915cdf1a36ce4c",
            "6ac7549c4b444e8f8460bf7f3fa8fc7d",
            "d0dfd74c2be54937aeadf99e41472dc6",
            "d61a72f3196641c2adfa89979b809c15",
            "487e501fb9f4493da3fd646f08e93298",
            "09239cc959e14aa48afda7e072d6a64f",
            "79d256f753ec4b6f98d7792bc8e58f22",
            "9da14f8820a5419bbd506234202dc53b",
            "e9aefa9657594067b1b529b40af6a4c3",
            "4001c0cb94a3424bb375a56080ab59ef",
            "80194e03a41d4d9e80a0a35bf8ab5daf",
            "59d6dcdb13ae4a9a84da1f00461cbead",
            "be11c7f017e94f87b72b372210c323e6",
            "8b91e1c7ab414eeaa8363d4522aac32e",
            "07ea24abdf8545bc9bad583a6a682841",
            "323e7626cfc84a59af962631603b90c8",
            "8d5f9371237844219278ad1cddf24bc4",
            "c63e4fcbc68f43d28695fbb1dab7ec7f",
            "547b627004d145f3bbd7fe214b76fc1d",
            "f4fcf800eeb347f99e39aba6905bd172",
            "656a80332eea4e869872097ade746100",
            "187f4916b7204d9ba8f991e3c1fe4981",
            "d26b38e1d6dc4a10a11fd0ca985fe338",
            "f7276f3264b04086b801e1fcc20dd1a4",
            "062f40ac3d51492e8330328d21f3a481",
            "fdd7fb5e9d9f42b89d9054051d3108d0",
            "1a0a2328787249ea997a5f81ede48fc4",
            "75140649a3294bf4a4fc48c253f5240d",
            "4dc70842143b448a93bc523259220f5e",
            "e8c4c1c648764c70b74325ca118e5d84",
            "b59ec07611144fc383346e5cbc11fa9e",
            "535e7cdfc01342dbb4de530750a9207c",
            "21d36eb3526d41e4b7ba978741b20ad3",
            "f4a4190219934ab58d6e7fa1fac60f49",
            "b819efc753b94d93a20808d74e6d1beb",
            "eeff6ff9db6a483aad10cc4a3b6c0cb0",
            "4ea3be6ef4be4235b49f6f101400d96d",
            "dc2d9e676da34b55a559731d3d667eeb",
            "96b71f94dba743798c369d5de9d5f689",
            "11b228861ad145a1ac29f4085650ea2e",
            "a9ec0c8e68394dc4b1a88434fb053865",
            "5794e6197db0445a9a27f1657d88649c",
            "e8da961985e84568b348da51ddb4b98c",
            "4c39b89e5b0f43dd8d4a1fcf64518684",
            "587cc023d8cd4a4dad16ea49ddeae309",
            "81da9f9f354b45799d1e8891d38c1a97",
            "87591ae6697a4ef584253a9551583df8",
            "d0478dd86c15426b988c30eacda849d6",
            "b8e339e7c3b846888a5eb3b3856eb5ae",
            "5796f31f051b41418227280c72733793",
            "f62ba8c2e176414c98ecf457c8452607",
            "545ce68c818b4d67a067f13031c4ff66",
            "b631a233c2314947b6a5901c2c8781fe",
            "2914ec38bfb94d2c92884ef296b4b7d4",
            "af7031baf6a345bdaf26520d7e726bd8",
            "11f4439dfe28416da728a30d75d691a4",
            "94efa36a603d437c9146bdace31d7420",
            "5a05016656db432a8ef46cd791606217",
            "4597dcaa1bda4c3da6259244fa343d34",
            "fecb6261b9254416b712cc6ff6969794",
            "c8e6fa1469ad4f24b732acae1e45e056",
            "63e4c058418a441a8ca69e32939ac60f",
            "1cfa4f23dc5b4670a43426ebc16b64bb",
            "3909324e870746188a41010ea0c7dee0",
            "6196fdd0573e49d48e4da2ebec8029cd"
          ]
        },
        "id": "4mxPSHBgb71w",
        "outputId": "06467afb-5b0a-4f2f-f6ec-75e1353298c4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50dc850c5fe445d5abe79b3e1fbe0f0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dea89111ca404469ba247c060b00bdad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6404e354eb04b98a315ad50e597128a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80a6ea88b75d4349821bdaa4e122db94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4fa8172bdaf442082b20482e7d5291f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4cabc2cb874b019e469d16c17cc260",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80194e03a41d4d9e80a0a35bf8ab5daf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "187f4916b7204d9ba8f991e3c1fe4981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21d36eb3526d41e4b7ba978741b20ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c39b89e5b0f43dd8d4a1fcf64518684",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af7031baf6a345bdaf26520d7e726bd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built/loaded FAISS indices for 3 categories.\n",
            "\n",
            "QUERY: The zebra crossing near the school has completely faded. What is the corrective action?\n",
            "CATEGORY: Road Marking\n",
            "SIM: 0.5295431543142993\n",
            "RESULT: **Recommended Intervention:** \n",
            "Intervention Type: Objects adjacent / near to carriageway\n",
            "Description: Subway piers, abutments, and culvert head walls outside the roadway must have at least six black and white stripes sloping 45 degrees towards traffic. Electrical poles near the carriageway should have horizontal black and white stripes up to 1.25 m high, with each stripe at least 100 mm wide. guard rails, guard stones or drums and trees that are not likely to be hit unless a vehicle runs off the carriageway shall be painted solid white. Trees must be marked up to 1.25 m height, with a 300 mm black band in the middle for visibility. All objects within 2.4 m of the shoulder or kerb must be painted. Object markers, at least 1.2 m high, should be placed in front of such objects to improve visibility. Kerbs of all islands in traffic flow must have 500 mm wide vertical black and white stripes.\n",
            "Code: IRC:35-2015\n",
            "Clause: 14.3\n",
            "\n",
            "**Database Reference:**\n",
            "- Intervention Type: Objects adjacent / near to carriageway\n",
            "- Code: IRC:35-2015\n",
            "- Clause: 14.3\n",
            "SOURCES:\n",
            "{'S. No.': 38, 'problem': 'Wrong Colour Selection', 'category': 'Road Marking', 'type': 'Objects adjacent / near to carriageway', 'code': 'IRC:35-2015', 'clause': '14.3', 'source_data': 'Subway piers, abutments, and culvert head walls outside the roadway must have at least six black and white stripes sloping 45 degrees towards traffic. Electrical poles near the carriageway should have horizontal black and white stripes up to 1.25 m high, with each stripe at least 100 mm wide. guard rails, guard stones or drums and trees that are not likely to be hit unless a vehicle runs off the carriageway shall be painted solid white. Trees must be marked up to 1.25 m height, with a 300 mm black band in the middle for visibility. All objects within 2.4 m of the shoulder or kerb must be painted. Object markers, at least 1.2 m high, should be placed in front of such objects to improve visibility. Kerbs of all islands in traffic flow must have 500 mm wide vertical black and white stripes.'}\n",
            "{'S. No.': 26, 'problem': 'Faded', 'category': 'Road Marking', 'type': 'Chequer Block Marking', 'code': 'IRC:35-2015', 'clause': '11.1.2', 'source_data': 'Chequer block marking (BM05) are painted in checkered blocks on carriageway for easy referencing such as marking for speed breaker. Speed breaker comprises of two rows of checkered markings consisting of alternate black and white bands of 500 mm width on either side of tapering. The application of thermoplastic paint for block marking is generally different from longitudinal marking. The quality of block marking with adequate visibility is of utmost importance. This marking is of 500 mm length, 500 mm breadth, 500 mm gap in between and is painted in white.'}\n",
            "{'S. No.': 28, 'problem': 'Faded', 'category': 'Road Marking', 'type': 'Broken Traffic Lane Line Marking', 'code': 'IRC:35-2015', 'clause': '4.2', 'source_data': 'The carriageway having two or more in one direction are divided into separate lanes by traffic lane line marking for vehicles to move in proper lanes and to discourage the meandering tendency of the drivers, thereby promoting safety and ensuring maximum capacity. Traffic lane markings should be applied near pedestrian crossings, hazardous locations, congested areas, and important one-way streets, ensuring proper implementation for safety. They must only be used where adequate lane width, as per IRC standards, is available between lane lines or the edge/center line. If sufficient width is not maintained, markings should be avoided to prevent side-swipe accidents. Broken traffic lanes can be crossed whereas continuous traffic lanes shall not be crossed and shall be white in colour. LM31 is of 15000 mm length with 3000 mm gap length and 200 mm width and shall be white in colour (as per Table A.1).'}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY: The hospital sign near the clinic has faded and is not visible at night.\n",
            "CATEGORY: Road Sign\n",
            "SIM: 0.32601943939370953\n",
            "RESULT: **Recommended Intervention:**\n",
            "Replace the faded hospital sign with a new one, ensuring it is visible at night. The new sign should conform to the specifications mentioned in the context, specifically the size (600 mm x 800 mm for normal sign and 450 mm x 600 mm for small sized sign), blue background, black symbol in a white square, and the blue band at the bottom for indicating distance to the facility.\n",
            "\n",
            "**Database Reference:**\n",
            "- Intervention Type: Hospital Sign\n",
            "- Code: IRC:67-2022\n",
            "- Clause: 17.8\n",
            "SOURCES:\n",
            "{'S. No.': 3, 'problem': 'Faded', 'category': 'Road Sign', 'type': 'Hospital Sign', 'code': 'IRC:67-2022', 'clause': '17.8', 'source_data': 'Hospital sign should be used to notify drivers of vehicles that they should take the precautions required near medical establishments and in particular that they should not make any unnecessary noise. The sign also serves to indicate the location of hospital where medical facilities will be available.\\nSign shall be rectangular and have a blue background, while black symbol shall be displayed in a white square to indicate the facility. The size of the normal sign shall be 600 mm x 800 mm and of the small sized sign 450 mm x 600 mm.On the blue band at the bottom of the sign, the distance to the facility indicated or to entry of the road leading to it, may be inscribed in white. Signs may also be set up at the entry to the road leading to the facility and may then bear a white directional arrow on the blue part at the bottom (as per clause 17.1).'}\n",
            "{'S. No.': 17, 'problem': 'Wrongly Placed', 'category': 'Road Sign', 'type': 'Pedestrian Crossing Informatory Signs', 'code': 'IRC:67-2022', 'clause': '2.3', 'source_data': 'Road signs shall be placed and operated in a consistent manner, positioned appropriately with respect to the location or situation to which they apply. Signs that are not necessary or no longer required shall be removed.'}\n",
            "{'S. No.': 15, 'problem': 'Wrongly Placed', 'category': 'Road Sign', 'type': 'Compulsory Turn Left Sign', 'code': 'IRC:67-2022', 'clause': '2.3', 'source_data': 'Road signs shall be placed and operated in a consistent manner, positioned appropriately with respect to the location or situation to which they apply. Signs that are not necessary or no longer required shall be removed.'}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY: The centerline marking on the two-way road is barely visible.\n",
            "CATEGORY: Road Marking\n",
            "SIM: 0.6003814925643015\n",
            "RESULT: **Recommended Intervention:** Direction Information NO ENTRY Marking\n",
            "\n",
            "**Database Reference:**\n",
            "- Intervention Type: Direction Information NO ENTRY Marking\n",
            "- Code: IRC:35-2015\n",
            "- Clause: 2.7\n",
            "SOURCES:\n",
            "{'S. No.': 25, 'problem': 'Visibility Issue', 'category': 'Road Marking', 'type': 'Direction Information NO ENTRY Marking', 'code': 'IRC:35-2015', 'clause': '2.7', 'source_data': 'Road markings must be clearly visible day and night, providing essential guidance, especially on unlit roads. Drivers shall detect markings at least two seconds ahead and that minimum preview distance with respect to speed is as follows: For <30 km/h: 17 m; 30\\x9640 km/h: 22 m; 40\\x9650 km/h: 28 m; 50\\x9665 km/h: 36 m; 65\\x9670 km/h: 39 m; 70\\x9680 km/h: 44 m; 80\\x9690 km/h: 50 m; 90\\x96100 km/h: 56 m; 100\\x96110 km/h: 61 m; 110\\x96120 km/h: 67 m. Visibility improves with wider lines, higher mark-to-gap ratios, and increased retro-reflectivity. These factors help drivers detect the markings according to design speed of roadway.'}\n",
            "{'S. No.': 28, 'problem': 'Faded', 'category': 'Road Marking', 'type': 'Broken Traffic Lane Line Marking', 'code': 'IRC:35-2015', 'clause': '4.2', 'source_data': 'The carriageway having two or more in one direction are divided into separate lanes by traffic lane line marking for vehicles to move in proper lanes and to discourage the meandering tendency of the drivers, thereby promoting safety and ensuring maximum capacity. Traffic lane markings should be applied near pedestrian crossings, hazardous locations, congested areas, and important one-way streets, ensuring proper implementation for safety. They must only be used where adequate lane width, as per IRC standards, is available between lane lines or the edge/center line. If sufficient width is not maintained, markings should be avoided to prevent side-swipe accidents. Broken traffic lanes can be crossed whereas continuous traffic lanes shall not be crossed and shall be white in colour. LM31 is of 15000 mm length with 3000 mm gap length and 200 mm width and shall be white in colour (as per Table A.1).'}\n",
            "{'S. No.': 21, 'problem': 'Visibility Issue', 'category': 'Road Marking', 'type': 'Word Message TRAM & BUS ONLY Marking', 'code': 'IRC:35-2015', 'clause': '2.7', 'source_data': 'Road markings must be clearly visible day and night, providing essential guidance, especially on unlit roads. Drivers shall detect markings at least two seconds ahead and that minimum preview distance with respect to speed is as follows: For <30 km/h: 17 m; 30\\x9640 km/h: 22 m; 40\\x9650 km/h: 28 m; 50\\x9665 km/h: 36 m; 65\\x9670 km/h: 39 m; 70\\x9680 km/h: 44 m; 80\\x9690 km/h: 50 m; 90\\x96100 km/h: 56 m; 100\\x96110 km/h: 61 m; 110\\x96120 km/h: 67 m. Visibility improves with wider lines, higher mark-to-gap ratios, and increased retro-reflectivity. These factors help drivers detect the markings according to design speed of roadway.'}\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "QUERY: There are deep potholes on the highway.\n",
            "CATEGORY: None\n",
            "SIM: None\n",
            "RESULT: Based on the provided database, I cannot find a specific intervention for this issue.\n",
            "SOURCES:\n",
            "{'S. No.': 11, 'problem': 'Damaged', 'category': 'Road Sign', 'type': 'Truck Lay-By Sign', 'code': 'IRC:67-2022', 'clause': '16.3.6', 'source_data': 'The provision of Truck Lay-by has become necessary and as such the truck drivers must be adequately informed of the availability of such a facility. Sign need to be provided with the directional arrow showing the direction in which the facility is located. These signs are to be posted in advance at 250 m and 500 m ahead of the location where truck lay-by is provided.\\nSigns may be in the shape of an elongated rectangle and colour pattern will be green background with letters in white. The size of letters depends on design speed of road which can be refered in Table 12.1. On the sign arrow showing truck lay-by direction need to be provided at 45 degree on the left side.'}\n",
            "{'S. No.': 1, 'problem': 'Damaged', 'category': 'Road Sign', 'type': 'STOP Sign', 'code': 'IRC:67-2022', 'clause': '14.4', 'source_data': 'The \\'STOP\\' sign, used on Minor Roads intersecting Major Roads, requires vehicles to stop before entering and proceed only when safe. It is octagonal with a red background, a white border, and \"STOP\" written centrally in white. Installed on the left side of the approach, it should be placed close to the stop line, typically 1.5 m in advance, without impairing visibility of the Major Road.\\nThe dimensions vary by approach speed: up to 50 km/h, 750 mm height, 25 mm border, 175 mm font; 51\\x9665 km/h, 900 mm height, 30 mm border, 210 mm font; and over 65 km/h, 1200 mm height, 40 mm border, 280 mm font.'}\n",
            "{'S. No.': 6, 'problem': 'Obstruction', 'category': 'Road Sign', 'type': 'Crash Prone Area Ahead Sign', 'code': 'IRC:67-2022', 'clause': '11.2', 'source_data': 'Drivers and other road users must have a clear and unobstructed view of road signs to ensure safe navigation. The area that shall remain free from obstructions to the sight line, whether caused by vegetation (e.g., bushes, trees), other signs, or street furniture (e.g., crash barriers), is referred to as the clear visibility distance. This distance shall increase as traffic speeds rise to provide sufficient reaction time. Road signs or their supports (including front and back) shall not display any form of advertisement or message unrelated to traffic control (as per clause 2.3).'}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Upgraded RAG pipeline (category-filtered FAISS indices + LCEL pipeline)\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# LangChain / huggingface imports (for LCEL / Groq setup)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# LCEL style imports (LangChain 0.3+)\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM (Groq)\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Config / paths\n",
        "# ---------------------------\n",
        "CSV_PATH = \"/content/GPT_Input_DB(Sheet1).csv\"  # update if needed\n",
        "ENCODING = \"latin1\"\n",
        "FAISS_BASE_DIR = \"faiss_indices_by_category\"   # where per-category indices are saved\n",
        "EMBED_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "os.makedirs(FAISS_BASE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load CSV & preprocess\n",
        "# ---------------------------\n",
        "df = pd.read_csv(CSV_PATH, encoding=ENCODING)\n",
        "df = df.fillna('')\n",
        "\n",
        "# Normalize column names\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "required = ['S. No.', 'problem', 'category', 'type', 'data', 'code', 'clause']\n",
        "for r in required:\n",
        "    if r not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {r}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Build documents by category\n",
        "# ---------------------------\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "docs_by_cat = defaultdict(list)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    problem = str(row['problem']).strip()\n",
        "    category = str(row['category']).strip()\n",
        "    typ = str(row['type']).strip()\n",
        "    desc = str(row['data']).strip()\n",
        "    code = str(row['code']).strip()\n",
        "    clause = str(row['clause']).strip()\n",
        "    sno = row['S. No.']\n",
        "\n",
        "    page_content = (\n",
        "        f\"Problem: {problem}\\n\"\n",
        "        f\"Category: {category}\\n\"\n",
        "        f\"Intervention Type: {typ}\\n\"\n",
        "        f\"Description: {desc}\\n\"\n",
        "        f\"Code: {code}\\n\"\n",
        "        f\"Clause: {clause}\\n\"\n",
        "    )\n",
        "\n",
        "    metadata = {\n",
        "        \"S. No.\": sno,\n",
        "        \"problem\": problem,\n",
        "        \"category\": category,\n",
        "        \"type\": typ,\n",
        "        \"code\": code,\n",
        "        \"clause\": clause,\n",
        "        \"source_data\": desc\n",
        "    }\n",
        "\n",
        "    doc = Document(page_content=page_content, metadata=metadata)\n",
        "    docs_by_cat[category].append(doc)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Instantiate embeddings\n",
        "# ---------------------------\n",
        "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Build/load FAISS indices by category + centroids\n",
        "# ---------------------------\n",
        "category_centroids = {}\n",
        "vectorstores = {}\n",
        "\n",
        "for cat, docs in docs_by_cat.items():\n",
        "\n",
        "    safe_cat = cat.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    idx_dir = os.path.join(FAISS_BASE_DIR, f\"faiss_{safe_cat}\")\n",
        "\n",
        "    if os.path.exists(idx_dir) and os.listdir(idx_dir):\n",
        "        vs = FAISS.load_local(idx_dir, embeddings, allow_dangerous_deserialization=True)\n",
        "    else:\n",
        "        vs = FAISS.from_documents(docs, embeddings)\n",
        "        vs.save_local(idx_dir)\n",
        "\n",
        "    vectorstores[cat] = vs\n",
        "\n",
        "    # compute centroid\n",
        "    text_embs = embeddings.embed_documents([d.page_content for d in docs])\n",
        "    centroid = np.mean(np.array(text_embs), axis=0)\n",
        "    category_centroids[cat] = centroid\n",
        "\n",
        "print(f\"Built/loaded FAISS indices for {len(vectorstores)} categories.\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Category selection helper\n",
        "# ---------------------------\n",
        "def choose_category_for_query(query, top_n=1):\n",
        "    q_emb = embeddings.embed_query(query)\n",
        "    cats = list(category_centroids.keys())\n",
        "    centroids = np.stack([category_centroids[c] for c in cats], axis=0)\n",
        "\n",
        "    q = np.array(q_emb)\n",
        "    q_norm = np.linalg.norm(q) + 1e-12\n",
        "    cent_norms = np.linalg.norm(centroids, axis=1) + 1e-12\n",
        "\n",
        "    sims = (centroids @ q) / (cent_norms * q_norm)\n",
        "\n",
        "    order = np.argsort(-sims)\n",
        "    top_cats = [cats[i] for i in order[:top_n]]\n",
        "\n",
        "    return top_cats, sims[order[0]]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 6) RAG Pipeline w/ LCEL\n",
        "# ---------------------------\n",
        "prompt_template = \"\"\"\n",
        "You are an expert AI assistant for the National Road Safety Hackathon 2025.\n",
        "Your SOLE purpose is to answer the user's question using ONLY the 'Provided Context'.\n",
        "\n",
        "If the context is empty or irrelevant, respond exactly with:\n",
        "\"Based on the provided database, I cannot find a specific intervention for this issue.\"\n",
        "\n",
        "**Provided Context:**\n",
        "{context}\n",
        "\n",
        "**User's Issue:**\n",
        "{question}\n",
        "\n",
        "**Recommended Intervention:**\n",
        "[Your answer]\n",
        "\n",
        "**Database Reference:**\n",
        "- Intervention Type: [from context]\n",
        "- Code: [from context]\n",
        "- Clause: [from context]\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.0)\n",
        "\n",
        "\n",
        "def format_docs_for_prompt(docs):\n",
        "    out = []\n",
        "    for d in docs:\n",
        "        md = d.metadata\n",
        "        out.append(\n",
        "            f\"Intervention Type: {md['type']}\\n\"\n",
        "            f\"Description: {md['source_data']}\\n\"\n",
        "            f\"Code: {md['code']}\\n\"\n",
        "            f\"Clause: {md['clause']}\"\n",
        "        )\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "\n",
        "EMPTY_MSG = \"Based on the provided database, I cannot find a specific intervention for this issue.\"\n",
        "\n",
        "\n",
        "def run_rag_query(query: str, k: int = 3, min_cat_sim: float = 0.1):\n",
        "\n",
        "    # 1) Category selection\n",
        "    top_cats, top_sim = choose_category_for_query(query, top_n=3)\n",
        "\n",
        "    if top_sim < min_cat_sim:\n",
        "        return {\"result\": EMPTY_MSG, \"source_documents\": []}\n",
        "\n",
        "    for cat in top_cats:\n",
        "\n",
        "        vs = vectorstores.get(cat)\n",
        "        retriever = vs.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "        # FIX APPLIED HERE\n",
        "        docs = retriever.invoke(query)\n",
        "\n",
        "        docs = [d for d in docs if d.metadata[\"category\"] == cat]\n",
        "        if not docs:\n",
        "            continue\n",
        "\n",
        "        # Build context\n",
        "        context = format_docs_for_prompt(docs)\n",
        "        if not context.strip():\n",
        "            continue\n",
        "\n",
        "        # Run LLM\n",
        "        final_prompt = PROMPT.format(context=context, question=query)\n",
        "        response = llm.invoke(final_prompt)\n",
        "\n",
        "        result = response.content.strip()\n",
        "\n",
        "        if EMPTY_MSG in result:\n",
        "            return {\"result\": EMPTY_MSG, \"source_documents\": docs}\n",
        "\n",
        "        return {\n",
        "            \"result\": result,\n",
        "            \"source_documents\": docs,\n",
        "            \"category\": cat,\n",
        "            \"category_similarity\": float(top_sim)\n",
        "        }\n",
        "\n",
        "    return {\"result\": EMPTY_MSG, \"source_documents\": []}\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Test queries\n",
        "# ---------------------------\n",
        "tests = [\n",
        "    \"The zebra crossing near the school has completely faded. What is the corrective action?\",\n",
        "    \"The hospital sign near the clinic has faded and is not visible at night.\",\n",
        "    \"The centerline marking on the two-way road is barely visible.\",\n",
        "    \"There are deep potholes on the highway.\",\n",
        "]\n",
        "\n",
        "for q in tests:\n",
        "    out = run_rag_query(q)\n",
        "    print(\"\\nQUERY:\", q)\n",
        "    print(\"CATEGORY:\", out.get(\"category\"))\n",
        "    print(\"SIM:\", out.get(\"category_similarity\"))\n",
        "    print(\"RESULT:\", out[\"result\"])\n",
        "    print(\"SOURCES:\")\n",
        "    for s in out[\"source_documents\"]:\n",
        "        print(s.metadata)\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "FipQHskEQnki",
        "outputId": "4766902d-27eb-4440-ee04-13973659e82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading CSV data...\n",
            "Building documents by category...\n",
            "Loading embeddings model...\n",
            "Building/loading FAISS indices...\n",
            "\u2713 Built/loaded FAISS indices for 3 categories.\n",
            "Initializing LLM...\n",
            "Launching Gradio interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fe4cd547ebebbe4f59.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fe4cd547ebebbe4f59.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Gradio Chat Interface for Road Safety RAG Pipeline\n",
        "import gradio as gr\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# LangChain / huggingface imports\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Config / paths\n",
        "# ---------------------------\n",
        "CSV_PATH = \"/content/GPT_Input_DB(Sheet1).csv\"  # update if needed\n",
        "ENCODING = \"latin1\"\n",
        "FAISS_BASE_DIR = \"faiss_indices_by_category\"\n",
        "EMBED_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "os.makedirs(FAISS_BASE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Load CSV & preprocess\n",
        "# ---------------------------\n",
        "print(\"Loading CSV data...\")\n",
        "df = pd.read_csv(CSV_PATH, encoding=ENCODING)\n",
        "df = df.fillna('')\n",
        "\n",
        "# Normalize column names\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "required = ['S. No.', 'problem', 'category', 'type', 'data', 'code', 'clause']\n",
        "for r in required:\n",
        "    if r not in df.columns:\n",
        "        raise ValueError(f\"Missing required column: {r}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Build documents by category\n",
        "# ---------------------------\n",
        "print(\"Building documents by category...\")\n",
        "docs_by_cat = defaultdict(list)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    problem = str(row['problem']).strip()\n",
        "    category = str(row['category']).strip()\n",
        "    typ = str(row['type']).strip()\n",
        "    desc = str(row['data']).strip()\n",
        "    code = str(row['code']).strip()\n",
        "    clause = str(row['clause']).strip()\n",
        "    sno = row['S. No.']\n",
        "\n",
        "    page_content = (\n",
        "        f\"Problem: {problem}\\n\"\n",
        "        f\"Category: {category}\\n\"\n",
        "        f\"Intervention Type: {typ}\\n\"\n",
        "        f\"Description: {desc}\\n\"\n",
        "        f\"Code: {code}\\n\"\n",
        "        f\"Clause: {clause}\\n\"\n",
        "    )\n",
        "\n",
        "    metadata = {\n",
        "        \"S. No.\": sno,\n",
        "        \"problem\": problem,\n",
        "        \"category\": category,\n",
        "        \"type\": typ,\n",
        "        \"code\": code,\n",
        "        \"clause\": clause,\n",
        "        \"source_data\": desc\n",
        "    }\n",
        "\n",
        "    doc = Document(page_content=page_content, metadata=metadata)\n",
        "    docs_by_cat[category].append(doc)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Instantiate embeddings\n",
        "# ---------------------------\n",
        "print(\"Loading embeddings model...\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Build/load FAISS indices by category + centroids\n",
        "# ---------------------------\n",
        "print(\"Building/loading FAISS indices...\")\n",
        "category_centroids = {}\n",
        "vectorstores = {}\n",
        "\n",
        "for cat, docs in docs_by_cat.items():\n",
        "    safe_cat = cat.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "    idx_dir = os.path.join(FAISS_BASE_DIR, f\"faiss_{safe_cat}\")\n",
        "\n",
        "    if os.path.exists(idx_dir) and os.listdir(idx_dir):\n",
        "        vs = FAISS.load_local(idx_dir, embeddings, allow_dangerous_deserialization=True)\n",
        "    else:\n",
        "        vs = FAISS.from_documents(docs, embeddings)\n",
        "        vs.save_local(idx_dir)\n",
        "\n",
        "    vectorstores[cat] = vs\n",
        "\n",
        "    # compute centroid\n",
        "    text_embs = embeddings.embed_documents([d.page_content for d in docs])\n",
        "    centroid = np.mean(np.array(text_embs), axis=0)\n",
        "    category_centroids[cat] = centroid\n",
        "\n",
        "print(f\"\u2713 Built/loaded FAISS indices for {len(vectorstores)} categories.\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Category selection helper\n",
        "# ---------------------------\n",
        "def choose_category_for_query(query, top_n=1):\n",
        "    q_emb = embeddings.embed_query(query)\n",
        "    cats = list(category_centroids.keys())\n",
        "    centroids = np.stack([category_centroids[c] for c in cats], axis=0)\n",
        "\n",
        "    q = np.array(q_emb)\n",
        "    q_norm = np.linalg.norm(q) + 1e-12\n",
        "    cent_norms = np.linalg.norm(centroids, axis=1) + 1e-12\n",
        "\n",
        "    sims = (centroids @ q) / (cent_norms * q_norm)\n",
        "\n",
        "    order = np.argsort(-sims)\n",
        "    top_cats = [cats[i] for i in order[:top_n]]\n",
        "\n",
        "    return top_cats, sims[order[0]]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 6) RAG Pipeline\n",
        "# ---------------------------\n",
        "prompt_template = \"\"\"\n",
        "You are an expert AI assistant for the National Road Safety Hackathon 2025.\n",
        "Your SOLE purpose is to answer the user's question using ONLY the 'Provided Context'.\n",
        "\n",
        "If the context is empty or irrelevant, respond exactly with:\n",
        "\"Based on the provided database, I cannot find a specific intervention for this issue.\"\n",
        "\n",
        "**Provided Context:**\n",
        "{context}\n",
        "\n",
        "**User's Issue:**\n",
        "{question}\n",
        "\n",
        "**Recommended Intervention:**\n",
        "[Your answer]\n",
        "\n",
        "**Database Reference:**\n",
        "- Intervention Type: [from context]\n",
        "- Code: [from context]\n",
        "- Clause: [from context]\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "print(\"Initializing LLM...\")\n",
        "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\", temperature=0.0)\n",
        "\n",
        "\n",
        "def format_docs_for_prompt(docs):\n",
        "    out = []\n",
        "    for d in docs:\n",
        "        md = d.metadata\n",
        "        out.append(\n",
        "            f\"Intervention Type: {md['type']}\\n\"\n",
        "            f\"Description: {md['source_data']}\\n\"\n",
        "            f\"Code: {md['code']}\\n\"\n",
        "            f\"Clause: {md['clause']}\"\n",
        "        )\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "\n",
        "EMPTY_MSG = \"Based on the provided database, I cannot find a specific intervention for this issue.\"\n",
        "\n",
        "\n",
        "def run_rag_query(query: str, k: int = 3, min_cat_sim: float = 0.1):\n",
        "    # 1) Category selection\n",
        "    top_cats, top_sim = choose_category_for_query(query, top_n=3)\n",
        "\n",
        "    if top_sim < min_cat_sim:\n",
        "        return {\"result\": EMPTY_MSG, \"source_documents\": [], \"category\": None, \"similarity\": 0.0}\n",
        "\n",
        "    for cat in top_cats:\n",
        "        vs = vectorstores.get(cat)\n",
        "        retriever = vs.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "        docs = retriever.invoke(query)\n",
        "        docs = [d for d in docs if d.metadata[\"category\"] == cat]\n",
        "        if not docs:\n",
        "            continue\n",
        "\n",
        "        # Build context\n",
        "        context = format_docs_for_prompt(docs)\n",
        "        if not context.strip():\n",
        "            continue\n",
        "\n",
        "        # Run LLM\n",
        "        final_prompt = PROMPT.format(context=context, question=query)\n",
        "        response = llm.invoke(final_prompt)\n",
        "\n",
        "        result = response.content.strip()\n",
        "\n",
        "        if EMPTY_MSG in result:\n",
        "            return {\"result\": EMPTY_MSG, \"source_documents\": docs, \"category\": cat, \"similarity\": float(top_sim)}\n",
        "\n",
        "        return {\n",
        "            \"result\": result,\n",
        "            \"source_documents\": docs,\n",
        "            \"category\": cat,\n",
        "            \"similarity\": float(top_sim)\n",
        "        }\n",
        "\n",
        "    return {\"result\": EMPTY_MSG, \"source_documents\": [], \"category\": None, \"similarity\": 0.0}\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Gradio Chat Interface\n",
        "# ---------------------------\n",
        "def format_response_with_metadata(result_dict):\n",
        "    \"\"\"Format the response with metadata in a nice readable way\"\"\"\n",
        "    response = result_dict['result']\n",
        "\n",
        "    # Add metadata section\n",
        "    if result_dict.get('category'):\n",
        "        response += f\"\\n\\n---\\n**\ud83d\udcca Metadata:**\\n\"\n",
        "        response += f\"- **Category:** {result_dict['category']}\\n\"\n",
        "        response += f\"- **Similarity Score:** {result_dict['similarity']:.2%}\\n\"\n",
        "\n",
        "        # Add source documents\n",
        "        if result_dict.get('source_documents'):\n",
        "            response += f\"\\n**\ud83d\udcda Source References:**\\n\"\n",
        "            for i, doc in enumerate(result_dict['source_documents'][:3], 1):\n",
        "                md = doc.metadata\n",
        "                response += f\"\\n{i}. **{md['type']}**\\n\"\n",
        "                response += f\"   - Code: `{md['code']}`\\n\"\n",
        "                response += f\"   - Clause: `{md['clause']}`\\n\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def chat_interface(message, history):\n",
        "    \"\"\"Process chat message and return response\"\"\"\n",
        "    if not message.strip():\n",
        "        return \"\"\n",
        "\n",
        "    # Run RAG query\n",
        "    result = run_rag_query(message)\n",
        "\n",
        "    # Format response with metadata\n",
        "    formatted_response = format_response_with_metadata(result)\n",
        "\n",
        "    # Return formatted response for Gradio chat\n",
        "    return formatted_response\n",
        "\n",
        "\n",
        "# Example queries for quick start\n",
        "examples = [\n",
        "    \"The zebra crossing near the school has completely faded. What is the corrective action?\",\n",
        "    \"The hospital sign near the clinic has faded and is not visible at night.\",\n",
        "    \"The centerline marking on the two-way road is barely visible.\",\n",
        "    \"There are deep potholes on the highway.\",\n",
        "    \"Speed limit signs are missing on the main road.\",\n",
        "]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Create Gradio Interface\n",
        "# ---------------------------\n",
        "print(\"Launching Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Road Safety Assistant\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # \ud83d\udea6 National Road Safety Hackathon 2025 - AI Assistant\n",
        "\n",
        "    **Welcome!** Describe any road safety issue, and I'll recommend appropriate interventions from the official database.\n",
        "    \"\"\")\n",
        "\n",
        "    chatbot = gr.Chatbot(\n",
        "        height=500,\n",
        "        label=\"Road Safety Assistant\",\n",
        "        show_label=True,\n",
        "        type=\"messages\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Describe a road safety issue (e.g., 'Faded zebra crossing near school')...\",\n",
        "            show_label=False,\n",
        "            scale=9,\n",
        "            container=False\n",
        "        )\n",
        "        submit_btn = gr.Button(\"Send \ud83d\ude80\", scale=1, variant=\"primary\")\n",
        "\n",
        "    with gr.Row():\n",
        "        clear = gr.ClearButton([msg, chatbot], value=\"Clear Chat \ud83d\uddd1\ufe0f\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=msg,\n",
        "        label=\"\ud83d\udccb Try these examples:\"\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ### \u2139\ufe0f How to use:\n",
        "    1. Type or select a road safety issue from the examples\n",
        "    2. Get instant recommendations with official code references\n",
        "    3. Review the metadata for detailed source information\n",
        "\n",
        "    **Powered by:** FAISS + LangChain + Groq LLM\n",
        "    \"\"\")\n",
        "\n",
        "    # Event handlers\n",
        "    def respond(message, history):\n",
        "        if not message.strip():\n",
        "            return history\n",
        "\n",
        "        # Run RAG query\n",
        "        result = run_rag_query(message)\n",
        "\n",
        "        # Format response with metadata\n",
        "        bot_response = format_response_with_metadata(result)\n",
        "\n",
        "        # Append to history in correct format\n",
        "        history.append({\"role\": \"user\", \"content\": message})\n",
        "        history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
        "\n",
        "        return history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [chatbot]).then(\n",
        "        lambda: \"\", None, msg\n",
        "    )\n",
        "    submit_btn.click(respond, [msg, chatbot], [chatbot]).then(\n",
        "        lambda: \"\", None, msg\n",
        "    )\n",
        "\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        share=True,  # Creates a public link (remove if not needed)\n",
        "        debug=True,\n",
        "        server_name=\"0.0.0.0\",  # Makes it accessible on your network\n",
        "        server_port=7860\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgzQrKdqSDuo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}